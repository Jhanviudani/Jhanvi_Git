{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "58653e07-11d6-46c4-8238-9488dd19f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "928d5394-9d04-42a7-874e-5dca718693ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/rajshah/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21731bf7-aa15-4f8c-93e7-e67a68d4b141",
   "metadata": {},
   "source": [
    "First, I want to gather my corpus of documents - that will be all of the script data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "583ba5fd-5983-41ad-88e2-3206df4e3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [] # Initializing empty list to store scene data\n",
    "\n",
    "# Iterate over all scene files in the directory\n",
    "\n",
    "for f in os.listdir('Dataset/allScenes'):\n",
    "    if not f.endswith('.csv'):\n",
    "        continue\n",
    "    filename = f.split('_scenes.csv')[0]\n",
    "    scenes = pd.read_csv('Dataset/allScenes/' + f, index_col=False).total_tokens.values\n",
    "    full_tokens = []\n",
    "    full_scenes = []\n",
    "\n",
    "    for scene in scenes:\n",
    "        scene_x = ast.literal_eval(scene)\n",
    "        full_scenes.append([token for token in scene_x if token in words])\n",
    "        full_tokens += scene_x\n",
    "    full_tokens = [token for token in full_tokens if token in words]\n",
    "    df.append({\n",
    "        'movie_filename': filename,\n",
    "        'tokens': full_tokens,\n",
    "        'text': (' ').join(full_tokens),\n",
    "        'scenes': full_scenes\n",
    "    })\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e6634fd4-32bb-4795-85b2-b6f8752cd274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_filename</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text</th>\n",
       "      <th>scenes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Easy-A</td>\n",
       "      <td>[go, two, town, neighboring, every, video, con...</td>\n",
       "      <td>go two town neighboring every video confess lo...</td>\n",
       "      <td>[[go, two, town, neighboring, every, video, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Killers-Of-The-Flower-Moon-Read-The-Screenplay</td>\n",
       "      <td>[sacred, teaching, white, bury, gave, pah, gra...</td>\n",
       "      <td>sacred teaching white bury gave pah grandfathe...</td>\n",
       "      <td>[[sacred, teaching, white, bury, gave, pah, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cast-Away</td>\n",
       "      <td>[pretty, gas, way, get, cut, mountain, filter,...</td>\n",
       "      <td>pretty gas way get cut mountain filter engine ...</td>\n",
       "      <td>[[pretty], [gas, way, get, cut, mountain, filt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ghost-Ship</td>\n",
       "      <td>[work, cabin, mind, friendship, find, know, ma...</td>\n",
       "      <td>work cabin mind friendship find know main talk...</td>\n",
       "      <td>[[work, cabin, mind, friendship, find, know, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Downsizing</td>\n",
       "      <td>[afraid, know, happen, make, right, born, thin...</td>\n",
       "      <td>afraid know happen make right born thing old g...</td>\n",
       "      <td>[[afraid, know, happen, make, right, born, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Bourne-Ultimatum-The</td>\n",
       "      <td>[radio, give, argument, gun, would, last, ago,...</td>\n",
       "      <td>radio give argument gun would last ago pam thr...</td>\n",
       "      <td>[[radio, give, argument, gun], [would, last, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Happy-Go-Lucky</td>\n",
       "      <td>[bit, dance, make, test, framing, holding, cel...</td>\n",
       "      <td>bit dance make test framing holding celebrate ...</td>\n",
       "      <td>[[bit, dance, make, test, framing, holding, ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Blind-Side-The</td>\n",
       "      <td>[investigate, trouble, bit, find, know, grange...</td>\n",
       "      <td>investigate trouble bit find know granger file...</td>\n",
       "      <td>[[investigate], [trouble, bit, find, know, gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Croods-The</td>\n",
       "      <td>[find, last, hope, would, every, three, fun, n...</td>\n",
       "      <td>find last hope would every three fun neighbor ...</td>\n",
       "      <td>[[find, last, hope, would, every, three, fun, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Trainspotting</td>\n",
       "      <td>[television, opener, family, compact, machine,...</td>\n",
       "      <td>television opener family compact machine elect...</td>\n",
       "      <td>[[television, opener, family, compact, machine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     movie_filename  \\\n",
       "0                                            Easy-A   \n",
       "1    Killers-Of-The-Flower-Moon-Read-The-Screenplay   \n",
       "2                                         Cast-Away   \n",
       "3                                        Ghost-Ship   \n",
       "4                                        Downsizing   \n",
       "..                                              ...   \n",
       "791                            Bourne-Ultimatum-The   \n",
       "792                                  Happy-Go-Lucky   \n",
       "793                                  Blind-Side-The   \n",
       "794                                      Croods-The   \n",
       "795                                   Trainspotting   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [go, two, town, neighboring, every, video, con...   \n",
       "1    [sacred, teaching, white, bury, gave, pah, gra...   \n",
       "2    [pretty, gas, way, get, cut, mountain, filter,...   \n",
       "3    [work, cabin, mind, friendship, find, know, ma...   \n",
       "4    [afraid, know, happen, make, right, born, thin...   \n",
       "..                                                 ...   \n",
       "791  [radio, give, argument, gun, would, last, ago,...   \n",
       "792  [bit, dance, make, test, framing, holding, cel...   \n",
       "793  [investigate, trouble, bit, find, know, grange...   \n",
       "794  [find, last, hope, would, every, three, fun, n...   \n",
       "795  [television, opener, family, compact, machine,...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    go two town neighboring every video confess lo...   \n",
       "1    sacred teaching white bury gave pah grandfathe...   \n",
       "2    pretty gas way get cut mountain filter engine ...   \n",
       "3    work cabin mind friendship find know main talk...   \n",
       "4    afraid know happen make right born thing old g...   \n",
       "..                                                 ...   \n",
       "791  radio give argument gun would last ago pam thr...   \n",
       "792  bit dance make test framing holding celebrate ...   \n",
       "793  investigate trouble bit find know granger file...   \n",
       "794  find last hope would every three fun neighbor ...   \n",
       "795  television opener family compact machine elect...   \n",
       "\n",
       "                                                scenes  \n",
       "0    [[go, two, town, neighboring, every, video, co...  \n",
       "1    [[sacred, teaching, white, bury, gave, pah, gr...  \n",
       "2    [[pretty], [gas, way, get, cut, mountain, filt...  \n",
       "3    [[work, cabin, mind, friendship, find, know, m...  \n",
       "4    [[afraid, know, happen, make, right, born, thi...  \n",
       "..                                                 ...  \n",
       "791  [[radio, give, argument, gun], [would, last, a...  \n",
       "792  [[bit, dance, make, test, framing, holding, ce...  \n",
       "793  [[investigate], [trouble, bit, find, know, gra...  \n",
       "794  [[find, last, hope, would, every, three, fun, ...  \n",
       "795  [[television, opener, family, compact, machine...  \n",
       "\n",
       "[796 rows x 4 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "61f7ed77-8755-4194-97aa-85e70d5baadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer() # Initializing TF-IDF Vectorizer\n",
    "tfidf = tfidf.fit(df.text.values) # Fitting the vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b71216d0-85ea-4573-b318-24a1471d6141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transforming data\n",
    "X_tf = tfidf.transform(df.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0e97a5be-ff12-41af-9435-bfaf17db9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing data in a DataFrame\n",
    "n=pd.DataFrame(X_tf.toarray(), columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e978f-5e07-4aee-ac77-edbef3ff56a8",
   "metadata": {},
   "source": [
    "Now, I want to look at each individual scene, and give them a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a4dc6722-d20e-4f30-8d00-114463712f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([df, n],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "99042738-b46a-426d-ad3f-d0c61e650d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f4638e45-ad6c-4ea5-af88-cff7e692bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in full.iterrows():\n",
    "    file = 'Dataset/allScenes/' + row.movie_filename + '_scenes.csv'\n",
    "    \n",
    "    # Extract importance score based on TF-IDF values\n",
    "\n",
    "    movieImportance = (row[list(tfidf.get_feature_names_out())].values)\n",
    "    scenes = row.scenes\n",
    "    x = (tfidf.transform([' '.join(scene) for scene in scenes]))\n",
    "    scaledArray = scaler.fit_transform(cosine_similarity(x, X_tf[index]))\n",
    "    pd_file = pd.read_csv(file)\n",
    "\n",
    "    # Add importance scores to the DataFrame\n",
    "\n",
    "    pd_file['importance'] = scaledArray\n",
    "    pd_file['movie_filename'] = row.movie_filename\n",
    "    pd_file.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae628298-9ea0-453f-9867-29ca492f0107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
